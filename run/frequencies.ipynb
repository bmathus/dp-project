{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bec5691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matusbojko/Desktop/DP/dp-project/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matusbojko/Desktop/DP/dp-project\n",
      "LICENSE           main.ipynb        \u001b[1m\u001b[36mproject\u001b[m\u001b[m/\n",
      "README.md         \u001b[1m\u001b[36mnotebooks\u001b[m\u001b[m/        requirements.txt\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m/             \u001b[31mprepare.sh\u001b[m\u001b[m*       \u001b[1m\u001b[36mrun\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.datamodule import BaseDataSets, RandomGenerator,TwoStreamBatchSampler,patients_to_slices\n",
    "from project.utils import worker_init_fn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import zoom\n",
    "from medpy import metric\n",
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5dfcc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Labeled samples: 5.0%\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "torch.cuda.manual_seed(1337)\n",
    "torch.mps.manual_seed(1337)\n",
    "\n",
    "\n",
    "db_train = BaseDataSets(base_dir=\"./data/ACDC\", split=\"train\", num=None, transform=transforms.Compose([\n",
    "    RandomGenerator([256, 256])\n",
    "]))\n",
    "\n",
    "db_val = BaseDataSets(base_dir=\"./data/ACDC\", split=\"val\")\n",
    "\n",
    "total_slices = len(db_train)\n",
    "labeled_slice = patients_to_slices(\"ACDC\", 7)\n",
    "labeled_idxs = list(range(0, labeled_slice))\n",
    "unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "\n",
    "batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, 24, 24-12)\n",
    "\n",
    "trainloader = DataLoader(db_train,num_workers=4,batch_size=1, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valloader = DataLoader(db_val, batch_size=1, shuffle=False,num_workers=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f995523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def visualize_label(label_tensor):\n",
    "    label_np = label_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    class_names = [\"Background\", \"RV\", \"MYO\", \"LV\"]\n",
    "    cmap = plt.get_cmap('nipy_spectral', 4)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    im = plt.imshow(label_np, cmap=cmap, vmin=0, vmax=3)\n",
    "    plt.colorbar(im, ticks=[0, 1, 2, 3])\n",
    "\n",
    "    # Add label legend\n",
    "    patches = [mpatches.Patch(color=cmap(i), label=f\"{i}: {name}\") for i, name in enumerate(class_names)]\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.title(\"Segmentation Label\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b340541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_class_pixel_distribution(trainloader, num_classes):\n",
    "    print(\"| Computing class pixel distribution...\")\n",
    "\n",
    "    class_counts = np.zeros(num_classes, dtype=np.int64)\n",
    "    total_pixels = 0\n",
    "\n",
    "    for batch in trainloader:\n",
    "        label = batch[\"label\"]  # shape: [1, H, W]\n",
    "        label = label.long().squeeze(0)  # shape: [H, W]\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            class_counts[c] += torch.sum(label == c).item()\n",
    "\n",
    "        total_pixels += label.numel()\n",
    "\n",
    "    class_freqs = class_counts / total_pixels\n",
    "    print(\"| Class pixel counts:\", class_counts)\n",
    "    print(\"| Class frequencies:\", class_freqs)\n",
    "\n",
    "    return class_freqs\n",
    "\n",
    "\n",
    "def get_alpha_from_freqs(freqs):\n",
    "    inv_freqs = 1.0 / (freqs + 1e-6)  # Avoid division by zero\n",
    "    alpha = inv_freqs / np.sum(inv_freqs)  # Normalize\n",
    "    print(\"| Computed alpha (class weights):\", alpha)\n",
    "    return alpha.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c9bd91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Computing class pixel distribution...\n",
      "| Class pixel counts: [82696537  1059178  1115352  1112165]\n",
      "| Class frequencies: [0.96177516 0.01231843 0.01297174 0.01293467]\n",
      "| Computed alpha (class weights): [0.00439447 0.34307564 0.32579818 0.32673171]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4  # ACDC has 4 classes: background, RV, MYO, LV\n",
    "\n",
    "freqs = compute_class_pixel_distribution(trainloader, num_classes)\n",
    "alpha = get_alpha_from_freqs(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "| Computing class pixel distribution...\n",
    "| Class pixel counts: [69406955   850234   960049   932202]\n",
    "| Class frequencies: [0.96198882 0.01178435 0.0133064  0.01292043]\n",
    "| Computed alpha (class weights): [0.00435986 0.35587794 0.31517398 0.32458822]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
