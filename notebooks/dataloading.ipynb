{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matusbojko/Desktop/dp-project\n",
      "LICENSE           main.ipynb        \u001b[1m\u001b[36mproject\u001b[m\u001b[m/\n",
      "README.md         \u001b[1m\u001b[36mnotebooks\u001b[m\u001b[m/        requirements.txt\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m/             \u001b[31mprepare.sh\u001b[m\u001b[m*       \u001b[1m\u001b[36mrun\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.datamodule import BaseDataSets, RandomGenerator,TwoStreamBatchSampler,patients_to_slices\n",
    "from project.utils import worker_init_fn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import zoom\n",
    "from medpy import metric\n",
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_sample(image,label):\n",
    "\n",
    "    # Convert PyTorch tensor (image) to NumPy array and squeeze the channel dimension if necessary\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image_np = image  # Already a NumPy array\n",
    "    else:\n",
    "        image_np = image.numpy()  # Convert PyTorch tensor to NumPy array\n",
    "    \n",
    "    # Squeeze the singleton channel dimension (1, 254, 254) -> (254, 254)\n",
    "    if image_np.shape[0] == 1:\n",
    "        image_np = np.squeeze(image_np, axis=0)  # Remove the channel dimension\n",
    "\n",
    "    # Define a color map for the labels: 0 (background), 1, 2, 3\n",
    "    cmap = colors.ListedColormap(['black', 'red', 'green', 'blue'])  # Customize these colors as needed\n",
    "    bounds = [0, 1, 2, 3, 4]  # Boundaries for the label values\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot the image (assuming it's grayscale)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np, cmap='gray')  # Display image as grayscale\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Plot the label with the custom color map\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(label, cmap=cmap, norm=norm)  # Color the label based on defined cmap\n",
    "    plt.colorbar(ticks=[0, 1, 2, 3])  # Show the color bar with label values\n",
    "    plt.title('Colored Segmentation Mask')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Labeled samples: 5.0%\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "torch.cuda.manual_seed(1337)\n",
    "torch.mps.manual_seed(1337)\n",
    "\n",
    "\n",
    "db_train = BaseDataSets(base_dir=\"./data/ACDC\", split=\"train\", num=None, transform=transforms.Compose([\n",
    "    RandomGenerator([256, 256])\n",
    "]))\n",
    "\n",
    "db_val = BaseDataSets(base_dir=\"./data/ACDC\", split=\"val\")\n",
    "\n",
    "total_slices = len(db_train)\n",
    "labeled_slice = patients_to_slices(\"ACDC\", 7)\n",
    "labeled_idxs = list(range(0, labeled_slice))\n",
    "unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "\n",
    "batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, 24, 24-12)\n",
    "\n",
    "trainloader = DataLoader(db_train,num_workers=4,batch_size=1, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valloader = DataLoader(db_val, batch_size=1, shuffle=False,num_workers=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(512)\n",
      "tensor(154)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max = 10000\n",
    "min = 0\n",
    "for i_batch, sampled_batch in enumerate(trainloader):\n",
    "    volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "    if i_batch == 0:\n",
    "        max = volume_batch[0]\n",
    "        min = volume_batch[0]\n",
    "    \n",
    "    if volume_batch[0] > max:\n",
    "        max = volume_batch[0]\n",
    "    \n",
    "    if volume_batch[0] < min:\n",
    "        min = volume_batch[0]\n",
    "    \n",
    "print(max)\n",
    "print(min)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_volume_ds(image, label):\n",
    "    image, label = image.squeeze(0).cpu().detach().numpy(), label.squeeze(0).cpu().detach().numpy()\n",
    "    #(1, 10, 256, 224) squeeze-> (10,256, 224) -> detach (gradient not longer computed for tensor)\n",
    "\n",
    "    prediction = np.zeros_like(label)\n",
    "\n",
    "    for ind in range(image.shape[0]): \n",
    "        slice = image[ind, :, :] # (256, 224)\n",
    "        x, y = slice.shape[0], slice.shape[1] # 256, 224\n",
    "        slice = zoom(slice, (256 / x, 256 / y), order=0) # 1, 1.14 -> after zoom (256,256)\n",
    "        print(slice.shape)\n",
    "        input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().to(\"mps\") # ADD CUDA or TO DEVICE -> ([1, 1, 256, 256])\n",
    "        print(input.shape)\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            output_main, _, _, _ = net(input)\n",
    "            out = torch.argmax(torch.softmax(\n",
    "                output_main, dim=1), dim=1).squeeze(0)\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pred = zoom(out, (x / patch_size[0], y / patch_size[1]), order=0)\n",
    "            prediction[ind] = pred\n",
    "        metric_list = []\n",
    "        for i in range(1, classes):\n",
    "            metric_list.append(calculate_metric_percase(\n",
    "                prediction == i, label == i))\n",
    "        return metric_list\n",
    "\n",
    "def calculate_metric_percase(pred, gt):\n",
    "    pred[pred > 0] = 1\n",
    "    gt[gt > 0] = 1\n",
    "    if pred.sum() > 0:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        hd95 = metric.binary.hd95(pred, gt)\n",
    "        return dice, hd95\n",
    "    else:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/matusbojko/Desktop/dp-project/project/datamodule.py\", line 46, in __getitem__\n    sample = self.transform(sample)\nTypeError: 'NoneType' object is not callable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_batch, sampled_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      2\u001b[0m     volume_batch, label_batch \u001b[38;5;241m=\u001b[39m sampled_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], sampled_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print(volume_batch.shape)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# print(label_batch.shape)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# print(i_batch)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1465\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/_utils.py:715\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/matusbojko/Desktop/dp-project/project/datamodule.py\", line 46, in __getitem__\n    sample = self.transform(sample)\nTypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sampled_batch in enumerate(trainloader):\n",
    "    volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "\n",
    "    # print(volume_batch.shape)\n",
    "    # print(label_batch.shape)\n",
    "    # print(i_batch)\n",
    "\n",
    "    show_sample(volume_batch[0],label_batch[0])\n",
    "\n",
    "\n",
    "    if i_batch == 15:\n",
    "        break\n",
    "\n",
    "#     torch.Size([24, 1, 256, 256])\n",
    "# torch.Size([24, 256, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.cudnn.version())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
