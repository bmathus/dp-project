{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matusbojko/Desktop/dp-project\n",
      "LICENSE           main.ipynb        \u001b[31mprepare.sh\u001b[m\u001b[m*       requirements.txt\n",
      "README.md         \u001b[1m\u001b[36mnotebooks\u001b[m\u001b[m/        \u001b[1m\u001b[36mproject\u001b[m\u001b[m/          \u001b[1m\u001b[36mrun\u001b[m\u001b[m/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matusbojko/Desktop/dp-project/.venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.datamodule import BaseDataSets, RandomGenerator,TwoStreamBatchSampler,patients_to_slices\n",
    "from project.utils import worker_init_fn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import zoom\n",
    "from medpy import metric\n",
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_sample(image,label):\n",
    "\n",
    "    # Convert PyTorch tensor (image) to NumPy array and squeeze the channel dimension if necessary\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image_np = image  # Already a NumPy array\n",
    "    else:\n",
    "        image_np = image.numpy()  # Convert PyTorch tensor to NumPy array\n",
    "    \n",
    "    # Squeeze the singleton channel dimension (1, 254, 254) -> (254, 254)\n",
    "    if image_np.shape[0] == 1:\n",
    "        image_np = np.squeeze(image_np, axis=0)  # Remove the channel dimension\n",
    "\n",
    "    # Define a color map for the labels: 0 (background), 1, 2, 3\n",
    "    cmap = colors.ListedColormap(['black', 'red', 'green', 'blue'])  # Customize these colors as needed\n",
    "    bounds = [0, 1, 2, 3, 4]  # Boundaries for the label values\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot the image (assuming it's grayscale)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np, cmap='gray')  # Display image as grayscale\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Plot the label with the custom color map\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(label, cmap=cmap, norm=norm)  # Color the label based on defined cmap\n",
    "    plt.colorbar(ticks=[0, 1, 2, 3])  # Show the color bar with label values\n",
    "    plt.title('Colored Segmentation Mask')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package           Version\n",
      "----------------- -----------\n",
      "appnope           0.1.4\n",
      "asttokens         2.4.1\n",
      "comm              0.2.2\n",
      "debugpy           1.8.7\n",
      "decorator         5.1.1\n",
      "executing         2.1.0\n",
      "ipykernel         6.29.5\n",
      "ipython           8.28.0\n",
      "jedi              0.19.1\n",
      "jupyter_client    8.6.3\n",
      "jupyter_core      5.7.2\n",
      "matplotlib-inline 0.1.7\n",
      "nest-asyncio      1.6.0\n",
      "packaging         24.1\n",
      "parso             0.8.4\n",
      "pexpect           4.9.0\n",
      "pip               24.2\n",
      "platformdirs      4.3.6\n",
      "prompt_toolkit    3.0.48\n",
      "psutil            6.0.0\n",
      "ptyprocess        0.7.0\n",
      "pure_eval         0.2.3\n",
      "Pygments          2.18.0\n",
      "python-dateutil   2.9.0.post0\n",
      "pyzmq             26.2.0\n",
      "six               1.16.0\n",
      "stack-data        0.6.3\n",
      "tornado           6.4.1\n",
      "traitlets         5.14.3\n",
      "wcwidth           0.2.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Labeled samples: 5.0%\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "torch.cuda.manual_seed(1337)\n",
    "torch.mps.manual_seed(1337)\n",
    "\n",
    "\n",
    "db_train = BaseDataSets(base_dir=\"./project/ACDC\", split=\"train\", num=None, transform=transforms.Compose([\n",
    "    RandomGenerator([256, 256])\n",
    "]))\n",
    "\n",
    "db_val = BaseDataSets(base_dir=\"./project/ACDC\", split=\"val\")\n",
    "\n",
    "total_slices = len(db_train)\n",
    "labeled_slice = patients_to_slices(\"ACDC\", 7)\n",
    "labeled_idxs = list(range(0, labeled_slice))\n",
    "unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "\n",
    "batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, 24, 24-12)\n",
    "\n",
    "trainloader = DataLoader(db_train, batch_sampler=batch_sampler,num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valloader = DataLoader(db_val, batch_size=1, shuffle=False,num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_volume_ds(image, label):\n",
    "    image, label = image.squeeze(0).cpu().detach().numpy(), label.squeeze(0).cpu().detach().numpy()\n",
    "    #(1, 10, 256, 224) squeeze-> (10,256, 224) -> detach (gradient not longer computed for tensor)\n",
    "\n",
    "    prediction = np.zeros_like(label)\n",
    "\n",
    "    for ind in range(image.shape[0]): \n",
    "        slice = image[ind, :, :] # (256, 224)\n",
    "        x, y = slice.shape[0], slice.shape[1] # 256, 224\n",
    "        slice = zoom(slice, (256 / x, 256 / y), order=0) # 1, 1.14 -> after zoom (256,256)\n",
    "        print(slice.shape)\n",
    "        input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().to(\"mps\") # ADD CUDA or TO DEVICE -> ([1, 1, 256, 256])\n",
    "        print(input.shape)\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            output_main, _, _, _ = net(input)\n",
    "            out = torch.argmax(torch.softmax(\n",
    "                output_main, dim=1), dim=1).squeeze(0)\n",
    "            out = out.cpu().detach().numpy()\n",
    "            pred = zoom(out, (x / patch_size[0], y / patch_size[1]), order=0)\n",
    "            prediction[ind] = pred\n",
    "        metric_list = []\n",
    "        for i in range(1, classes):\n",
    "            metric_list.append(calculate_metric_percase(\n",
    "                prediction == i, label == i))\n",
    "        return metric_list\n",
    "\n",
    "def calculate_metric_percase(pred, gt):\n",
    "    pred[pred > 0] = 1\n",
    "    gt[gt > 0] = 1\n",
    "    if pred.sum() > 0:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        hd95 = metric.binary.hd95(pred, gt)\n",
    "        return dice, hd95\n",
    "    else:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(256, 256)\n",
      "torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sampled_batch in enumerate(valloader):\n",
    "    volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "    test_single_volume_ds(volume_batch,label_batch)\n",
    "    # print(volume_batch.shape)\n",
    "    # print(label_batch.shape)\n",
    "    # print(i_batch)\n",
    "\n",
    "    # show_sample(volume_batch[0][0],label_batch[0][0])\n",
    "\n",
    "\n",
    "    if i_batch == 0:\n",
    "        break\n",
    "\n",
    "#     torch.Size([24, 1, 256, 256])\n",
    "# torch.Size([24, 256, 256])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
